<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tutorial on Everyday Statistics</title>
    <link>https://SamLeeBYU.github.io/tags/tutorial/</link>
    <description>Recent content in tutorial on Everyday Statistics</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Sep 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://SamLeeBYU.github.io/tags/tutorial/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Web Scraping Using Selenium: Best Practices and Example</title>
      <link>https://SamLeeBYU.github.io/2023/09/29/selenium-best-practices/</link>
      <pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate>
      
      <guid>https://SamLeeBYU.github.io/2023/09/29/selenium-best-practices/</guid>
      <description>Introduction In this tutorial I will walk through the code used for a basic model that I used to scrape through the traffic citations database stored on the BYU server.
(Though the example is particularly directed towards BYU students, the structure and syntax of the example can be applied anywhere)
All code is posted in this on my Github here.
Through my experiences of trial and error and much headache of not being able to figure out why my code isn&amp;rsquo;t working, and by watching countless tutorials myself, I want to make this tutorial to demonstrate the best way I found to go about scraping data.</description>
    </item>
    
  </channel>
</rss>
